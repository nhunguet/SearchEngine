{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"The quick brown fox jumps over the lazy dog.\"\n",
    "web_documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",  # Identical\n",
    "    \"The quick brown fox jumps.\",  # Similar\n",
    "    \"A lazy dog sleeps under the tree.\",  # Less similar\n",
    "    \"The fast red cat chases the mouse.\"  # Unrelated\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Method Results:\n",
      "Document: The quick brown fox jumps over the lazy dog., Score: 1.00\n",
      "Document: The quick brown fox jumps., Score: 0.54\n",
      "\n",
      "Discovery Method Results:\n",
      "Pair: (The quick brown fox jumps over the lazy dog., The quick brown fox jumps.), Score: 0.54\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def jaccard_similarity(doc1, doc2):\n",
    "    \"\"\"Calculates Jaccard similarity between two documents.\"\"\"\n",
    "    set1 = set(doc1.split())\n",
    "    set2 = set(doc2.split())\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "def similarity_score(doc1, doc2):\n",
    "    \"\"\"Calculates similarity score using Jaccard similarity and SequenceMatcher.\"\"\"\n",
    "    jaccard_sim = jaccard_similarity(doc1, doc2)\n",
    "    seq_matcher = SequenceMatcher(None, doc1, doc2)\n",
    "    seq_sim = seq_matcher.ratio()\n",
    "    # Combine scores with a weight (adjust as needed)\n",
    "    combined_score = (jaccard_sim * 0.6) + (seq_sim * 0.4) \n",
    "    return combined_score\n",
    "\n",
    "def search_method(document, web_documents, threshold=0.5):\n",
    "    \"\"\"Finds nearly identical documents from a set of web documents.\"\"\"\n",
    "    results = []\n",
    "    for web_doc in web_documents:\n",
    "        score = similarity_score(document, web_doc)\n",
    "        if score >= threshold:\n",
    "            results.append((web_doc, score))\n",
    "    return results\n",
    "\n",
    "def discovery_method(web_documents, threshold=0.5):\n",
    "    \"\"\"Finds pairs of nearly identical documents within a set.\"\"\"\n",
    "    results = []\n",
    "    for i in range(len(web_documents) - 1):\n",
    "        for j in range(i + 1, len(web_documents)):\n",
    "            doc1 = web_documents[i]\n",
    "            doc2 = web_documents[j]\n",
    "            score = similarity_score(doc1, doc2)\n",
    "            if score >= threshold:\n",
    "                results.append((doc1, doc2, score))\n",
    "    return results\n",
    "\n",
    "# Example Usage\n",
    "document = \"The quick brown fox jumps over the lazy dog.\"\n",
    "web_documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",  # Identical\n",
    "    \"The quick brown fox jumps.\",  # Similar\n",
    "    \"A lazy dog sleeps under the tree.\",  # Less similar\n",
    "    \"The fast red cat chases the mouse.\"  # Unrelated\n",
    "]\n",
    "\n",
    "# Search Method\n",
    "similar_docs = search_method(document, web_documents)\n",
    "print(\"Search Method Results:\")\n",
    "for doc, score in similar_docs:\n",
    "    print(f\"Document: {doc}, Score: {score:.2f}\")\n",
    "\n",
    "# Discovery Method\n",
    "identical_pairs = discovery_method(web_documents)\n",
    "print(\"\\nDiscovery Method Results:\")\n",
    "for doc1, doc2, score in identical_pairs:\n",
    "    print(f\"Pair: ({doc1}, {doc2}), Score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_flat_area(bits):\n",
    "    \"\"\"\n",
    "    Finds the largest flat area of the distribution in a sequence of bits.\n",
    "    A flat area is a region with mostly 0s that has maximum 1s outside it.\n",
    "\n",
    "    Args:\n",
    "        bits: A list of 0s and 1s, where 1 represents a tag and 0 represents a non-tag token.\n",
    "\n",
    "    Returns:\n",
    "        A tuple (i, j) where i is the start index and j is the end index of the flat area.\n",
    "    \"\"\"\n",
    "    n = len(bits)\n",
    "    if n == 0:\n",
    "        return 0, 0\n",
    "\n",
    "    max_len = 0\n",
    "    best_i = 0\n",
    "    best_j = 0\n",
    "    current_len = 0\n",
    "    current_start = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if bits[i] == 0:\n",
    "            if current_len == 0:\n",
    "                current_start = i\n",
    "            current_len += 1\n",
    "        else:\n",
    "            if current_len > max_len:\n",
    "                max_len = current_len\n",
    "                best_i = current_start\n",
    "                best_j = i - 1\n",
    "            current_len = 0\n",
    "\n",
    "    if current_len > max_len:\n",
    "        max_len = current_len\n",
    "        best_i = current_start\n",
    "        best_j = n - 1\n",
    "\n",
    "    return best_i, best_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles are found in many Indo-European languages, Semitic languages, Polynesian languages, and even language isolates such as Basque; however, they are formally absent from many of the world's major languages including Chinese, Japanese, Korean, Mongolian, Tibetan, many Turkic languages (including Tatar, Bashkir, Tuvan and Chuvash), many Uralic languages (incl. Finnic[a] and Saami languages), Hindi-Urdu, Punjabi, the Dravidian languages (incl. Tamil, Telugu, and Kannada), the Baltic languages, the majority of Slavic languages, the Bantu languages (incl. Swahili). In some languages that do have articles, such as some North Caucasian languages, the use of articles is optional; however, in others like English and German it is mandatory in all cases.\n",
      "Linguists believe the common ancestor of the Indo-European languages, Proto-Indo-European, did not have articles. Most of the languages in this family do not have definite or indefinite articles: there is no article in Latin or Sanskrit, nor in some modern Indo-European languages, such as the families of Slavic languages (except for Bulgarian and Macedonian, which are rather distinctive among the Slavic languages in their grammar, and some Northern Russian dialects[7]), Baltic languages and many Indo-Aryan languages. Although Classical Greek had a definite article (which has survived into Modern Greek and which bears strong functional resemblance to the German definite article, which it is related to), the earlier Homeric Greek used this article largely as a pronoun or demonstrative, whereas the earliest known form of Greek known as Mycenaean Greek did not have any articles. Articles developed independently in several language families.\n",
      "Not all languages have both definite and indefinite articles, and some languages have different types of definite and indefinite articles to distinguish finer shades of meaning: for example, French and Italian have a partitive article used for indefinite mass nouns, whereas Colognian has two distinct sets of definite articles indicating focus and uniqueness, and Macedonian uses definite articles in a demonstrative sense, with a tripartite distinction (proximal, medial, distal) based on distance from the speaker or interlocutor. The words \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_5128\\4183472135.py:36: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  for element in soup.find_all(text=True):\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def find_largest_flat_area(bits):\n",
    "    max_len = 0\n",
    "    max_start = 0\n",
    "    current_start = 0\n",
    "    current_len = 0\n",
    "\n",
    "    for i, bit in enumerate(bits):\n",
    "        if bit == 1:\n",
    "            if current_len == 0:\n",
    "                current_start = i\n",
    "            current_len += 1\n",
    "        else:\n",
    "            if current_len > max_len:\n",
    "                max_len = current_len\n",
    "                max_start = current_start\n",
    "            current_len = 0\n",
    "\n",
    "    if current_len > max_len:\n",
    "        max_len = current_len\n",
    "        max_start = current_start\n",
    "\n",
    "    return max_start, max_start + max_len - 1\n",
    "\n",
    "def crawl_and_find_flat_area(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Define tags that are likely to contain significant text content\n",
    "    significant_tags = ['p', 'div', 'span', 'li', 'a', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']\n",
    "    \n",
    "    bits = []\n",
    "    text = []\n",
    "    for element in soup.find_all(text=True):\n",
    "        if element.parent.name in significant_tags:\n",
    "            bits.append(1)\n",
    "        else:\n",
    "            bits.append(0)\n",
    "        text.append(element)\n",
    "    \n",
    "    # Find the largest flat area\n",
    "    i, j = find_largest_flat_area(bits)\n",
    "    \n",
    "    # Cut the document by that area and return the text\n",
    "    return ''.join(text[i:j+1])\n",
    "\n",
    "# Example usage:\n",
    "url = 'https://en.wikipedia.org/wiki/Article_(grammar)'  # Replace with the actual URL\n",
    "result_text = crawl_and_find_flat_area(url)\n",
    "print(result_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
